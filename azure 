import logging from openai import AzureOpenAI from azure.identity import DefaultAzureCredential from azure.keyvault.secrets import SecretClient # Use your vault URI KEY_VAULT_URL = "https://kv-azureopenai-app.vault.azure.net/" # Initialize Key Vault client def load_config_from_vault(): credential = DefaultAzureCredential() client = SecretClient(vault_url=KEY_VAULT_URL, credential=credential) return { "api_key": client.get_secret("AzureLLMKey").value, "api_base": client.get_secret("AzureOpenAiBase").value, "model_version": client.get_secret("AzureOpenAiVersion").value, "deployment": client.get_secret("AzureOpenAiDeployment").value, } def author_proposal_section_with_llm( api_key: str, api_base: str, model_version: str, deployment: str, section_name: str, workspace_content: str ) -> str: prompt = f""" You are a professional proposal writer for a reputed IT Services enterprise. You will help draft a specific section of a business proposal based strictly on the content provided below from a Workspace. Your response must follow these principles: - Use only the information provided in the Workspace. Do not assume or invent additional content. - Maintain an enterprise-grade, business-professional tone. - Ensure that the writing reflects the company‚Äôs credibility, experience, and strategic value. - Use clear, confident, and well-structured language suitable for external stakeholders such as clients, procurement teams, and decision-makers. --- ### ‚úèÔ∏è Section to be Written: {section_name} ### üóÇ Workspace Content: \"\"\" {workspace_content} \"\"\" --- ‚úÖ Instructions: - Synthesize and summarize the workspace content into a coherent, well-written section. - If the content spans multiple ideas, organize them into logical paragraphs or bullet points as appropriate. - Do not repeat raw content or include citations/attributions. The output should be ready to copy-paste into a client-facing proposal. """ try: client = AzureOpenAI( azure_endpoint=api_base, api_key=api_key, api_version=model_version, ) response = client.chat.completions.create( model=deployment, temperature=0.3, max_tokens=1200, messages=[ {"role": "system", "content": prompt}, {"role": "user", "content": "Please generate the section content now."} ] ) return response.choices[0].message.content.strip() except Exception as e: logging.error(f"‚ùå Unexpected error during Azure OpenAI API call: {str(e)}") return f"‚ùå API call failed: {str(e)}" # Sample input section = "Solution Overview" workspace_data = """ Our cloud platform is built using Kubernetes and microservices, hosted on Azure. The delivery methodology follows Agile SCRUM with continuous integration pipelines. We integrate proprietary AI accelerators to improve deployment speed and reduce risk. """ # Load secrets from Azure Key Vault config = load_config_from_vault() print("Using API base:", config["api_base"]) print("Using model version:", config["model_version"]) print("Using deployment:", config["deployment"]) print("API Key starts with:", config["api_key"][:5], "... (hidden)") # Generate proposal section generated = author_proposal_section_with_llm( api_key=config["api_key"], api_base=config["api_base"], model_version=config["model_version"], deployment=config["deployment"], section_name=section, workspace_content=workspace_data ) print("\nGenerated Proposal Section:") print(generated)